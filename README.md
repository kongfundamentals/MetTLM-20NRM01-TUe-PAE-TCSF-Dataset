# MetTLM 20NRM01 TU/e Dataset: Measuring the temporal contrast sensitivity function of the phantom array effect

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.14454227.svg)](https://doi.org/10.5281/zenodo.14454227)

This repository provides the complete source code and data necessary to reproduce the main figures (Figures 2-10) from our recent publication:

> Xiangzhen Kong, Christophe Martinsons, Maria Nilsson Tengelin, & Ingrid Heynderickx. (2025). *Measuring the temporal contrast sensitivity function of the phantom array effect*. Lighting Research & Technology. DOI: [10.1177/14771535251379686](https://doi.org/10.1177/14771535251379686).

## How to Reproduce the Figures

To reproduce all figures from the paper, follow these steps in MATLAB:

**0. Unzip the external toolbox.** Before proceeding, ensure that `mQUESTPlus.zip` (located in `/external/`) has been unzipped into `/external/mQUESTPlus`. See the "Included Software: mQUESTPlus Toolbox" section for details.

**1. Run all preprocessing scripts.** This step needs to be performed only once to generate the processed data files required for plotting, which are derived from the core data analysis.
```matlab
% Run from the MATLAB command window, from the root directory of the project.
computeVisibilityThresholds
computeIndividualFits
createLiteratureDataset
```

**2. Run the master script.** Execute `runAllFigures` to generate all figures for the publication.
```matlab
runAllFigures
```
Alternatively, you can run any of the individual plotting scripts (e.g., `plotFigure5`, `plotFigure6`, etc.) to generate a specific figure. All outputs will be saved to the `/output` directory.

### Advanced Usage: Plotting Subsets of Participants
For flexible analysis, the plotting functions for Figures 5 and 7 support an optional input argument to visualize specific subsets of participants. The input must be a vector of participant IDs.

When run in this advanced mode, the output files will have a descriptive suffix (e.g., `fig5_participant_05.emf`) to avoid overwriting the main figure from the paper.

*   **To plot a single participant (e.g., Participant 5):**
    ```matlab
    plotFigure5(5)
    ```
*   **To plot a specific range (e.g., the first 10 participants):**
    ```matlab
    plotFigure5(1:10)
    ```

*   **To plot a non-sequential list of participants:**
    ```matlab
    plotFigure5([1 3 7 17])
    ```
*   **To exclude a specific participant (e.g., Participant 9):**
    ```matlab
    plotFigure5(setdiff(1:22, 9))
    ```

## System Requirements

*   MATLAB R2024a (or a newer/compatible version).
*   Required MATLAB Toolboxes:
    *   Statistics and Machine Learning Toolbox

## Repository Content and Structure

The repository follows this structure:

*   **/data/**: Contains all data files.
    *   `/rawData/`: Curated raw data from the current study.
    *   `/externalData/`: Curated datasets extracted from the literature for a comprehensive visualization and comparison.
    *   `/processedData/`: Data files generated by the preprocessing scripts.
*   **/src/**: Contains all MATLAB scripts.
    *   `/preprocessing/`: Scripts for data analysis and processing.
    *   `/utils/`: Helper functions used by other scripts.
    *   `/illustrations/`: Scripts for creating illustrative animations (e.g., for presentations).
*   **/external/**: Contains the required third-party toolbox (see the "Included Software: mQUESTPlus Toolbox" section below).
*   **/output/**: The default location where all generated figures and tables are saved.
*   `runAllFigures.m`: The master script to run the entire project.

### Included Software: mQUESTPlus Toolbox

To ensure full reproducibility and manage repository file limits (i.e., 100), the **mQUESTPlus** toolbox is provided as a `mQUESTPlus.zip` archive within the `/external` directory. **Before running any scripts, please unzip `mQUESTPlus.zip` directly into the `/external` folder, such that the toolbox files are located at `/external/mQUESTPlus`.** 

This toolbox was instrumental during the experiment for adapting the modulation depth of sinusoidal waveforms based on participant responses and is used in this repository for fitting psychometric functions.

*   **Original Author(s):** David Brainard (brainard@psych.upenn.edu).
*   **Original Repository:** [https://github.com/brainardlab/mQUESTPlus](https://github.com/brainardlab/mQUESTPlus)
*   **Version Used:** Commit `adb471184da4d69f9ffaf38ac8d5cd811f5d2b9e` (committed by David Brainard on April 18, 2023).

*   *Note on License:* The original repository contains an MIT license. This software is included here in good faith for the sole purpose of ensuring the reproducibility of this paper's results. For any use beyond reproducing this paper's results, please contact David Brainard (brainard@psych.upenn.edu). **The authors of this paper do NOT claim ownership of or provide warranty for this toolbox.**

### External Datasets for Comprehensive Literature Comparison (Figure 10)
The plot includes data curated from several external publications. As the raw data for these studies were not all openly available, data points were meticulously extracted from figures in the original publications using [PlotDigitizer](https://plotdigitizer.com/). The extracted data is provided in `.csv` format in the `/data/externalData/` directory. Full citations for the original sources are provided below.

*   **CIE 249:2022:** *CIE 249:2022 Visual Aspects of Time-Modulated Lighting Systems*. Vienna: CIE, 2022.
*   **Wang et al. (2017):** *P‐141: Phantom Array Effect of LED Lighting*. In: SID Symposium Digest of Technical Papers, Los Angeles, CA, USA, 21-26 May 2017; 48(1): 1804–1807. DOI: [10.1002/sdtp.12037](https://doi.org/10.1002/sdtp.12037).
*   **Yu et al. (2018):** *Influence of Frequency, Waveform and Colour on the Visibility of the Phantom Array Effect*. In: Proceedings of the CIE 2018 Topical Conference on Smart Lighting, Taipei, Chinese Taipei, 26-27 April 2018: 138-146. DOI: [10.25039/x45.2018.OP23](https://doi.org/10.25039/x45.2018.OP23).
*   **Kong et al. (2023):** *Dependence of Temporal Frequency and Chromaticity on the Visibility of the Phantom Array Effect*. In: Proceedings of the 30th Session of the CIE, Ljubljana, Slovenia, 15-23 September 2023: 347-356. DOI: [10.25039/x50.2023.OP060](https://doi.org/10.25039/x50.2023.OP060).
*   **Tan et al. (2024):** *Temporal light modulation: A phantom array visibility measure*. Lighting Research & Technology 2024; 56(7): 772-789. DOI: [10.1177/14771535241239611](https://doi.org/10.1177/14771535241239611).
    
*   *Note on Reproduction:* The data for Tan et al. (2024) and for CIE 249:2022 was extracted from figures in the Tan et al. (2024) paper. The equations provided in the text did not fully reproduce the published figures, so the visually presented data was used as the primary source.

## How to Cite
If you utilize the code or data from this repository, please cite both the associated publication and this software repository.

**1. Citing the Paper:**
> Xiangzhen Kong, Christophe Martinsons, Maria Nilsson Tengelin, & Ingrid Heynderickx. (2025). *Measuring the temporal contrast sensitivity function of the phantom array effect*. Lighting Research & Technology. DOI: [10.1177/14771535251379686](https://doi.org/10.1177/14771535251379686).

**2. Citing the Software/Dataset:**
> Xiangzhen Kong, Christophe Martinsons, Maria Nilsson Tengelin, & Ingrid Heynderickx. (2025). *MetTLM 20NRM01 TU/e Dataset: Measuring the temporal contrast sensitivity function of the phantom array effect* (Version 1.0.0) [Computer software]. Zenodo. [https://doi.org/10.5281/zenodo.14454227](https://doi.org/10.5281/zenodo.14454227).

**BibTeX Entry:**
```bibtex
@software{kong_2025_code,
  author       = {Kong, Xiangzhen and Martinsons, Christophe and Nilsson Tengelin, Maria and Heynderickx, Ingrid},
  title        = {{MetTLM 20NRM01 TU/e Dataset: Measuring the temporal contrast sensitivity function of the phantom array effect}},
  month        = {September},
  year         = {2025},
  publisher    = {Zenodo},
  version      = {1.0.0},
  doi          = {10.5281/zenodo.14454227},
  url          = {https://doi.org/10.5281/zenodo.14454227}
}
```

## Statement on the Use of AI Tools
While the core scientific algorithms and data analysis logic were designed and implemented by the authors, this repository was refactored and documented with the assistance of generative AI tools (primarily [Google AI Studio](https://aistudio.google.com/)) to enhance readability and adhere to FAIR principles. These tools assisted with tasks such as:
* Refactoring and cleaning code for improved readability and efficiency.
* Generating boilerplate code, such as plotting templates and file I/O operations.
* Assisting with debugging and error identification.
* Suggesting improvements for documentation and comments.

 All AI-generated content was critically reviewed, tested, and adapted by the authors to ensure it correctly implements the intended logic and meets the scientific standards of the project.

## Scope of this Repository
This repository contains all the necessary data and code to reproduce the main figures (Figures 2 through 10) presented in the associated publication. While this version focuses on reproducing the main figures, analysis and visualization code for supplementary material may be added in a future release. For specific inquiries regarding supplementary analyses, please contact the corresponding author at x.kong@tue.nl.

## License
This project consists of different components, which are covered by two different licenses.

### Source Code (MIT License)
All source code contained in this repository (all `.m` files) is licensed under the **[MIT License](https://opensource.org/license/mit)**. Please see the `LICENSE` file for the full text.

### Data and Documentation (CC BY 4.0 License)
The text of this `README.md` file, all figures generated in the `/output` directory, and all the raw and processed data tables (e.g., `table_S9_peakParameters.csv`) are licensed under the **[Creative Commons Attribution license (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/)**, in accordance with the open-access policy of the original publication.